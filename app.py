from flask import Flask, request, jsonify
import re
import pickle
import pandas as pd
import numpy as np
import logging
import os

app = Flask(__name__)
logging.basicConfig(level=logging.INFO)

# Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¿Ñ€Ğ¸ ÑÑ‚Ğ°Ñ€Ñ‚Ğµ ÑĞµÑ€Ğ²ĞµÑ€Ğ°
try:
    model_path = os.path.join(os.path.dirname(__file__), 'xgboost_token_model.pkl')
    with open(model_path, 'rb') as f:
        model_artifacts = pickle.load(f)
    print("âœ… ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ° ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾!")
except Exception as e:
    print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: {e}")
    model_artifacts = None

def parse_token_data(text):
    """
    ĞŸĞ°Ñ€ÑĞ¸Ñ‚ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ğ° Ğ² ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚
    ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ Ğ´Ğ»Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
    """
    try:
        token_data = {}
        
        # Market Cap - "MC: $136.8K"
        mcap_match = re.search(r'MC:\s*\$?([0-9,.]+)([KMB]?)', text, re.IGNORECASE)
        if mcap_match:
            value_str = mcap_match.group(1).replace(',', '')
            value = float(value_str)
            unit = mcap_match.group(2).upper()
            if unit == 'K':
                value *= 1000
            elif unit == 'M':
                value *= 1000000
            elif unit == 'B':
                value *= 1000000000
            token_data['market_cap'] = value
        else:
            token_data['market_cap'] = 0
        
        # Liquidity - "Liq: $42.4K"
        liq_match = re.search(r'Liq:\s*\$?([0-9,.]+)([KMB]?)', text, re.IGNORECASE)
        if liq_match:
            value_str = liq_match.group(1).replace(',', '')
            value = float(value_str)
            unit = liq_match.group(2).upper()
            if unit == 'K':
                value *= 1000
            elif unit == 'M':
                value *= 1000000
            elif unit == 'B':
                value *= 1000000000
            token_data['liquidity'] = value
        else:
            token_data['liquidity'] = 0
        
        # Volume - Ğ±ĞµÑ€ĞµĞ¼ 1min volume: "Volume: $12,129.12"
        vol_1min_match = re.search(r'1 min:.*?Volume:\s*\$?([0-9,.]+)', text, re.DOTALL)
        if vol_1min_match:
            value_str = vol_1min_match.group(1).replace(',', '')
            token_data['volume_1min'] = float(value_str)
        else:
            # Ğ•ÑĞ»Ğ¸ Ğ½ĞµÑ‚ 1min, Ğ±ĞµÑ€ĞµĞ¼ 5min
            vol_5min_match = re.search(r'5 min:.*?Volume:\s*\$?([0-9,.]+)', text, re.DOTALL)
            if vol_5min_match:
                value_str = vol_5min_match.group(1).replace(',', '')
                token_data['volume_1min'] = float(value_str)
            else:
                token_data['volume_1min'] = 0
        
        # Last Volume - Ğ½ĞµÑ‚ Ğ² Ğ½Ğ¾Ğ²Ğ¾Ğ¼ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ, ÑÑ‚Ğ°Ğ²Ğ¸Ğ¼ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ
        token_data['last_volume'] = token_data['volume_1min']  # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ğ¾Ğ±ÑŠĞµĞ¼
        token_data['last_volume_multiplier'] = 1.0
        
        # Token Age - "Token age: 25m"
        age_match = re.search(r'Token age:\s*(?:(\d+)h\s*)?(?:(\d+)m\s*)?(?:(\d+)s\s*)?', text, re.IGNORECASE)
        if age_match:
            hours = int(age_match.group(1)) if age_match.group(1) else 0
            minutes = int(age_match.group(2)) if age_match.group(2) else 0
            seconds = int(age_match.group(3)) if age_match.group(3) else 0
            total_minutes = hours * 60 + minutes + seconds / 60
            token_data['token_age_numeric'] = total_minutes
        else:
            token_data['token_age_numeric'] = 0
        
        # Ğ”ĞµÑ€Ğ¶Ğ°Ñ‚ĞµĞ»Ğ¸ Ğ¿Ğ¾ Ñ†Ğ²ĞµÑ‚Ğ°Ğ¼ - "ğŸŸ¢: 8 | ğŸ”µ: 5 | ğŸŸ¡: 12 | â­•ï¸: 42"
        holders_match = re.search(r'ğŸŸ¢:\s*(\d+)\s*\|\s*ğŸ”µ:\s*(\d+)\s*\|\s*ğŸŸ¡:\s*(\d+)\s*\|\s*â­•ï¸:\s*(\d+)', text)
        if holders_match:
            token_data['green_holders'] = int(holders_match.group(1))
            token_data['blue_holders'] = int(holders_match.group(2))
            token_data['yellow_holders'] = int(holders_match.group(3))
            token_data['circle_holders'] = int(holders_match.group(4))
        else:
            token_data['green_holders'] = 0
            token_data['blue_holders'] = 0
            token_data['yellow_holders'] = 0
            token_data['circle_holders'] = 0
        
        # Ğ¡Ğ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ´ĞµÑ€Ğ¶Ğ°Ñ‚ĞµĞ»Ğ¸ - "ğŸ¤¡: 0 | ğŸŒ: 0 | ğŸŒ—: 0 | ğŸŒš: 3"
        special_holders_match = re.search(r'ğŸ¤¡:\s*(\d+)\s*\|\s*ğŸŒ:\s*(\d+)\s*\|\s*ğŸŒ—:\s*(\d+)\s*\|\s*ğŸŒš:\s*(\d+)', text)
        if special_holders_match:
            token_data['clown_holders'] = int(special_holders_match.group(1))
            token_data['sun_holders'] = int(special_holders_match.group(2))
            token_data['half_moon_holders'] = int(special_holders_match.group(3))
            token_data['dark_moon_holders'] = int(special_holders_match.group(4))
        else:
            token_data['clown_holders'] = 0
            token_data['sun_holders'] = 0
            token_data['half_moon_holders'] = 0
            token_data['dark_moon_holders'] = 0
        
        # Total holders - "Total: 168"
        total_holders_match = re.search(r'Total:\s*(\d+)', text)
        if total_holders_match:
            token_data['total_holders'] = int(total_holders_match.group(1))
        else:
            token_data['total_holders'] = (
                token_data['green_holders'] + token_data['blue_holders'] + 
                token_data['yellow_holders'] + token_data['circle_holders']
            )
        
        # Top 10 percent - "Top 10: 23%"
        top10_match = re.search(r'Top 10:\s*([0-9.]+)%', text)
        if top10_match:
            token_data['top10_percent'] = float(top10_match.group(1))
        else:
            token_data['top10_percent'] = 50.0
        
        # Current/Initial percentages - "Current/Initial: 16.76% / 98.87%"
        current_initial_match = re.search(r'Current/Initial:\s*([0-9.]+)%\s*/\s*([0-9.]+)%', text)
        if current_initial_match:
            token_data['total_now_percent'] = float(current_initial_match.group(1))
            token_data['total_percent'] = float(current_initial_match.group(2))
        else:
            token_data['total_percent'] = 100.0
            token_data['total_now_percent'] = 50.0
        
        # Dev holds - "Dev current balance: 0%"
        dev_match = re.search(r'Dev current balance:\s*([0-9.]+)%', text)
        if dev_match:
            token_data['dev_holds_percent'] = float(dev_match.group(1))
        else:
            token_data['dev_holds_percent'] = 0.0
        
        # ĞŸĞ¾Ğ»Ñ ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… Ğ½ĞµÑ‚ Ğ² Ğ½Ğ¾Ğ²Ğ¾Ğ¼ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ - Ğ·Ğ°Ğ¿Ğ¾Ğ»Ğ½ÑĞµĞ¼ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸ÑĞ¼Ğ¸ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ
        token_data['insiders_count'] = 0
        token_data['insiders_percent'] = 0.0
        token_data['snipers_count'] = 0
        token_data['bundle_total'] = 0
        token_data['bundle_supply_percent'] = 0.0
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
        token_data['volume_to_liquidity'] = float(
            np.log1p(token_data['volume_1min']) / np.log1p(token_data['liquidity'] + 1)
            if token_data['liquidity'] > 0 else 0
        )
        
        # Ğ›Ğ¾Ğ³Ğ°Ñ€Ğ¸Ñ„Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸
        token_data['log_market_cap'] = float(np.log1p(token_data['market_cap']))
        token_data['log_liquidity'] = float(np.log1p(token_data['liquidity']))
        token_data['log_volume_1min'] = float(np.log1p(token_data['volume_1min']))
        token_data['log_last_volume'] = float(np.log1p(token_data['last_volume']))
        
        # ĞšĞ¾Ğ½Ñ†ĞµĞ½Ñ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ´ĞµÑ€Ğ¶Ğ°Ñ‚ĞµĞ»ĞµĞ¹
        token_data['holder_concentration'] = int(
            token_data['green_holders'] + token_data['blue_holders'] + 
            token_data['yellow_holders'] + token_data['circle_holders']
        )
        
        # Ğ Ğ¸ÑĞº-Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ñ‹
        token_data['total_risk_percent'] = float(
            token_data['dev_holds_percent'] + token_data['insiders_percent']
        )
        
        return convert_to_json_serializable(token_data)
        
    except Exception as e:
        logging.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ°: {e}")
        return {}

def convert_to_json_serializable(obj):
    """ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚ numpy Ñ‚Ğ¸Ğ¿Ñ‹ Ğ² ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğµ Python Ñ‚Ğ¸Ğ¿Ñ‹ Ğ´Ğ»Ñ JSON"""
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_to_json_serializable(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_to_json_serializable(item) for item in obj]
    else:
        return obj

def predict_token_success(token_data):
    """
    ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ÑÑ‚ÑŒ Ñ‚Ğ¾ĞºĞµĞ½Ğ° (Ñ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ´Ñ€Ğ¸Ñ„Ñ‚Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…)
    """
    if model_artifacts is None:
        return {'error': 'ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°'}
    
    try:
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ DataFrame
        df_new = pd.DataFrame([token_data])
        
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°ÑÑ‰Ğ¸Ğµ ÑÑ‚Ğ¾Ğ»Ğ±Ñ†Ñ‹
        for col in model_artifacts['feature_names']:
            if col not in df_new.columns:
                df_new[col] = 0
        
        # Ğ‘ĞµÑ€ĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½ÑƒĞ¶Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸ Ğ² Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ¿Ğ¾Ñ€ÑĞ´ĞºĞµ
        df_new = df_new[model_artifacts['feature_names']]
        
        # ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ Ğ¸Ğ¼Ğ¿ÑƒÑ‚ĞµÑ€
        df_imputed = pd.DataFrame(
            model_artifacts['imputer'].transform(df_new), 
            columns=model_artifacts['feature_names']
        )
        
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¸ÑÑ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
        raw_probability = float(model_artifacts['model'].predict_proba(df_imputed)[0, 1])
        
        # ğŸ”„ Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ˜Ğ• Ğ”Ğ Ğ˜Ğ¤Ğ¢Ğ: Ğ˜Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ
        probability = 1.0 - raw_probability
        prediction = int(probability >= 0.5)
        
        # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸
        confidence_score = abs(probability - 0.5) * 2
        if confidence_score > 0.8:
            confidence_level = "ĞÑ‡ĞµĞ½ÑŒ Ğ²Ñ‹ÑĞ¾ĞºĞ°Ñ"
        elif confidence_score > 0.6:
            confidence_level = "Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ"
        elif confidence_score > 0.4:
            confidence_level = "Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ"
        else:
            confidence_level = "ĞĞ¸Ğ·ĞºĞ°Ñ"
        
        # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ñ
        if probability >= 0.7:
            recommendation = "ĞŸĞĞšĞ£ĞŸĞĞ¢Ğ¬"
            risk_level = "ĞĞ¸Ğ·ĞºĞ¸Ğ¹"
        elif probability >= 0.5:
            recommendation = "Ğ˜Ğ—Ğ£Ğ§Ğ˜Ğ¢Ğ¬"
            risk_level = "Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğ¹"
        else:
            recommendation = "ĞŸĞ ĞĞŸĞ£Ğ¡Ğ¢Ğ˜Ğ¢Ğ¬"
            risk_level = "Ğ’Ñ‹ÑĞ¾ĞºĞ¸Ğ¹"
        
        result = {
            'prediction': 'Ğ”Ğ' if prediction == 1 else 'ĞĞ•Ğ¢',
            'probability': round(float(probability), 4),
            'probability_percent': f"{probability*100:.1f}%",
            'confidence_level': confidence_level,
            'confidence_score': round(float(confidence_score), 4),
            'recommendation': recommendation,
            'risk_level': risk_level,
            'threshold_conservative': 'Ğ”Ğ' if probability >= 0.7 else 'ĞĞ•Ğ¢',
            'threshold_optimal': 'Ğ”Ğ' if probability >= 0.5 else 'ĞĞ•Ğ¢',
            'threshold_aggressive': 'Ğ”Ğ' if probability >= 0.3 else 'ĞĞ•Ğ¢',
            
            # Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ†Ğ¸Ğ¸ Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ¸
            'model_info': {
                'raw_probability': round(raw_probability, 4),
                'corrected_probability': round(probability, 4),
                'drift_correction': True,
                'data_format': 'new_format_optimized'
            }
        }
        
        return convert_to_json_serializable(result)
        
    except Exception as e:
        logging.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ: {e}")
        return {'error': f'ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ: {str(e)}'}

@app.route('/health', methods=['GET'])
def health_check():
    """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ¾ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ API"""
    return jsonify({
        'status': 'healthy',
        'model_loaded': model_artifacts is not None,
        'version': '2.1',
        'optimized_for': 'new_data_format',
        'drift_correction': 'enabled',
        'environment': os.environ.get('RAILWAY_ENVIRONMENT', 'unknown')
    })

@app.route('/predict', methods=['POST'])
def predict():
    """ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚ Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ"""
    try:
        data = request.get_json()
        
        if not data or 'text' not in data:
            return jsonify({'error': 'ĞĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ»Ğµ "text" Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ñ‚Ğ¾ĞºĞµĞ½Ğ°'}), 400
        
        # ĞŸĞ°Ñ€ÑĞ¸Ğ¼ Ñ‚ĞµĞºÑÑ‚
        token_data = parse_token_data(data['text'])
        
        if not token_data:
            return jsonify({'error': 'ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ñ€Ğ°ÑĞ¿Ğ°Ñ€ÑĞ¸Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ğ°'}), 400
        
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ
        result = predict_token_success(token_data)
        
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ€Ğ°ÑĞ¿Ğ°Ñ€ÑĞµĞ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ¸
        if data.get('include_parsed_data', False):
            result['parsed_data'] = convert_to_json_serializable(token_data)
        
        return jsonify(result)
        
    except Exception as e:
        logging.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° API: {e}")
        return jsonify({'error': f'Ğ’Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½ÑÑ Ğ¾ÑˆĞ¸Ğ±ĞºĞ° ÑĞµÑ€Ğ²ĞµÑ€Ğ°: {str(e)}'}), 500

@app.route('/test', methods=['GET'])
def test():
    """Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚ Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ°"""
    test_text = """ğŸ² $PVE | President vs Elon

3nuogKUQuxfxjCRud7Bpm5a9Q7eT7mxpFGNe9WeNbonk

â³ Token age:  25m  | ğŸ‘ 14
â”œ MC: $136.8K
â”œ Liq: $42.4K / SOL pooled: 111.02
â”” ATH: $134.6K (-4% / 4s)

1 min:
â”œ Volume: $12,129.12
â”œ Buy volume ($): $6,446.81
â”œ Sell volume ($): $5,682.31
â”œ Buys: 165
â”” Sells: 177

5 min:
â”œ Volume: $71,175.80
â”œ Buy volume ($): $46,124.03
â”œ Sell volume ($): $25,051.77
â”œ Buys: 585
â”” Sells: 448

ğŸ¯ First 70 buyers:
ğŸŒšğŸŒšğŸŒšğŸŸ¡ğŸŸ¡ğŸŸ¡ğŸŸ¡ğŸŸ¡ğŸŸ¡ğŸŸ¡
ğŸŸ¡ğŸŸ¢ğŸŸ¡â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸
â­•ï¸ğŸŸ¢ğŸ”µğŸ”µğŸŸ¢ğŸŸ¢â­•ï¸ğŸŸ¡ğŸŸ¡â­•ï¸
â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸
â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸â­•ï¸ğŸŸ¢ğŸŸ¢
ğŸ”µâ­•ï¸â­•ï¸â­•ï¸ğŸŸ¢ğŸ”µâ­•ï¸â­•ï¸â­•ï¸â­•ï¸
ğŸ”µâ­•ï¸â­•ï¸â­•ï¸ğŸŸ¢â­•ï¸â­•ï¸â­•ï¸â­•ï¸ğŸŸ¡

â”œ ğŸŸ¢: 8 | ğŸ”µ: 5 | ğŸŸ¡: 12 | â­•ï¸: 42
â”œ ğŸ¤¡: 0 | ğŸŒ: 0 | ğŸŒ—: 0 | ğŸŒš: 3
â”œ Current/Initial: 16.76% / 98.87%

ğŸ‘¥ Holders:
â”œ Total: 168
â”œ Freshies: 8.8% 1D | 87% 7D
â”œ Top 10: 23%
ğŸ’° Top 10 Holding (%)
15.82 | 2.48 | 2.42 | 2.42 | 2.41 | 2.38 | 2.31 | 2.29 | 2.26 | 2.22

ğŸ˜ Dev
â”œ Dev current balance: 0%
â”” Dev SOL balance: 0 SOL

ğŸ”’ Security:
â”œ NoMint: ğŸŸ¢
â”œ Blacklist: ğŸŸ¢
â”œ Burnt: ğŸŸ¢
â”œ Dev Sold: ğŸŸ¢
â”” Dex Paid: ğŸ”´"""
    
    token_data = parse_token_data(test_text)
    result = predict_token_success(token_data)
    result['parsed_data'] = convert_to_json_serializable(token_data)
    
    return jsonify(result)

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    debug = os.environ.get('RAILWAY_ENVIRONMENT') != 'production'
    
    print("ğŸš€ Token Prediction API v2.1")
    print(f"ğŸ“ ĞŸĞ¾Ñ€Ñ‚: {port}")
    print(f"ğŸ”„ ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ´Ğ»Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…")
    print(f"ğŸ§ª Ğ¢ĞµÑÑ‚: /test")
    print(f"â¤ï¸  Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ: /health")
    
    app.run(host='0.0.0.0', port=port, debug=debug)
